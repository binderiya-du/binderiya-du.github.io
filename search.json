[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Boston, MA\nbeegii@bu.edu | 857-971-1133\n\n\n\nBoston University — Boston, MA\nMaster of Science in Applied Business Analytics — Expected Jan 2026\n- Relevant Coursework: Data Mining, Operations Management (Lean Six Sigma), Web Analytics, Marketing Analytics\nUniversity of Minnesota - Twin Cities — Minneapolis, MN\nBachelor of Science in Sustainable Systems Management — Dec 2020\n- Relevant Coursework: Renewable Energy, Environmental Policy, Life Cycle Analysis, Supply Chain Sustainability, Sustainable Manufacturing Principles and Practices\n\n\n\n\n\nR, PowerBI, SQL, Python, Control Charts, DMAIC\n\n\n\n\n\nBoston University — Boston, MA\nResearch Assistant & Teaching Assistant — Fall 2024 - Present\n- Teaching & Student Support: Conduct consultation sessions to assist students with course material, clarify concepts, and address academic concerns. Support grading assignments for a class with 25 students to ensure fair and timely evaluation.\n- Instructional Design & AI Integration: Utilized AI tools to create 20 tutorial videos for a business simulation, enhancing student engagement and learning. Assisted in designing instructional content to improve the student learning experience.\nKhev Khashmal, LLC — Ulaanbaatar, Mongolia\nBusiness Development Executive Assistant & Marketing Sales Specialist — 2021 - 2024\n- Strategic Growth & Operations: Collaborated with management consultants and stakeholders to develop strategies for market expansion and operational efficiency, successfully reducing operational costs by 5% despite launching a new production line and factory. Led cross-functional coordination to optimize workflows for smooth integration of new processes.\n- Business Strategy & Execution: Translated the CEO’s vision into measurable actions and KPIs, ensuring strategic alignment with business objectives. Assisted in implementing change management projects that streamlined operations, reducing delays by 20%.\n- Market Analysis & Sales Optimization: Conducted in-depth market research to identify trends and provide actionable insights, supporting data-driven decision-making. Spearheaded marketing initiatives that increased sales of a targeted product by 10% and boosted audience engagement by 20%.\nClean Water Action — Minneapolis, MN\nSustainability Advocate Intern — June 2019 – August 2019\n- Communicated complex environmental policies through presentations and educational sessions, effectively informing and engaging new members on key sustainability issues.\n- Led grassroots outreach initiatives to mobilize community support for environmental policies, increasing public awareness and advocacy engagement.\n\n\n\n\nChicago Crime and Crash Data Analysis — Boston University\nHackathon, Team Member (SQL, Python, PowerBI) — Fall 2024\n- Transformed crime and crash data for structured analysis and insights using SQL and Python.\n- Designed PowerBI dashboards to visualize crime trends, seasonal crash patterns, and financial impacts.\n- Identified key insights: theft (21.17%) and battery (17.77%) were most common crimes; 57% of crashes caused damages over $1,500, peaking in the afternoon.\nNew York City Neighborhood Real Estate Analysis — Boston University\nFar Rockaway Real Estate Analysis (Excel, R, PowerBI) — Fall 2024\n- Maximized net present value of real estate investment profits over 8-quarter period by modeling optimization tool.\n- Identified high-performing property clusters for targeted investments with R-based clustering analysis.\n- Enabled data-driven decision-making among stakeholders by designing interactive PowerBI dashboards.\nRestaurant Investment Decision Analysis — Boston University\nTeam Member, Microbrewery Investment Decision Analysis (Excel, Monte Carlo Business Simulation) — Fall 2024\n- Collaborated with a team to analyze financial and market data to evaluate a $150K investment in an in-house microbrewery.\n- Designed a financial model in Excel and presented insights to support the restaurant’s decision-making process.\n- Used Business Simulation Models for scenario analysis to assess potential risks and returns.\n\n\n\n\n\nLanguages: Mongolian (Fluent); Russian (Intermediate)\n\nInterests: Half Marathoner, Aspiring New York Marathoner, Growing Tennis Player\n\nEmail: binderiya.du@gmail.com"
  },
  {
    "objectID": "resume.html#binderiya-dugersuren",
    "href": "resume.html#binderiya-dugersuren",
    "title": "Resume",
    "section": "",
    "text": "Boston, MA\nbeegii@bu.edu | 857-971-1133\n\n\n\nBoston University — Boston, MA\nMaster of Science in Applied Business Analytics — Expected Jan 2026\n- Relevant Coursework: Data Mining, Operations Management (Lean Six Sigma), Web Analytics, Marketing Analytics\nUniversity of Minnesota - Twin Cities — Minneapolis, MN\nBachelor of Science in Sustainable Systems Management — Dec 2020\n- Relevant Coursework: Renewable Energy, Environmental Policy, Life Cycle Analysis, Supply Chain Sustainability, Sustainable Manufacturing Principles and Practices\n\n\n\n\n\nR, PowerBI, SQL, Python, Control Charts, DMAIC\n\n\n\n\n\nBoston University — Boston, MA\nResearch Assistant & Teaching Assistant — Fall 2024 - Present\n- Teaching & Student Support: Conduct consultation sessions to assist students with course material, clarify concepts, and address academic concerns. Support grading assignments for a class with 25 students to ensure fair and timely evaluation.\n- Instructional Design & AI Integration: Utilized AI tools to create 20 tutorial videos for a business simulation, enhancing student engagement and learning. Assisted in designing instructional content to improve the student learning experience.\nKhev Khashmal, LLC — Ulaanbaatar, Mongolia\nBusiness Development Executive Assistant & Marketing Sales Specialist — 2021 - 2024\n- Strategic Growth & Operations: Collaborated with management consultants and stakeholders to develop strategies for market expansion and operational efficiency, successfully reducing operational costs by 5% despite launching a new production line and factory. Led cross-functional coordination to optimize workflows for smooth integration of new processes.\n- Business Strategy & Execution: Translated the CEO’s vision into measurable actions and KPIs, ensuring strategic alignment with business objectives. Assisted in implementing change management projects that streamlined operations, reducing delays by 20%.\n- Market Analysis & Sales Optimization: Conducted in-depth market research to identify trends and provide actionable insights, supporting data-driven decision-making. Spearheaded marketing initiatives that increased sales of a targeted product by 10% and boosted audience engagement by 20%.\nClean Water Action — Minneapolis, MN\nSustainability Advocate Intern — June 2019 – August 2019\n- Communicated complex environmental policies through presentations and educational sessions, effectively informing and engaging new members on key sustainability issues.\n- Led grassroots outreach initiatives to mobilize community support for environmental policies, increasing public awareness and advocacy engagement.\n\n\n\n\nChicago Crime and Crash Data Analysis — Boston University\nHackathon, Team Member (SQL, Python, PowerBI) — Fall 2024\n- Transformed crime and crash data for structured analysis and insights using SQL and Python.\n- Designed PowerBI dashboards to visualize crime trends, seasonal crash patterns, and financial impacts.\n- Identified key insights: theft (21.17%) and battery (17.77%) were most common crimes; 57% of crashes caused damages over $1,500, peaking in the afternoon.\nNew York City Neighborhood Real Estate Analysis — Boston University\nFar Rockaway Real Estate Analysis (Excel, R, PowerBI) — Fall 2024\n- Maximized net present value of real estate investment profits over 8-quarter period by modeling optimization tool.\n- Identified high-performing property clusters for targeted investments with R-based clustering analysis.\n- Enabled data-driven decision-making among stakeholders by designing interactive PowerBI dashboards.\nRestaurant Investment Decision Analysis — Boston University\nTeam Member, Microbrewery Investment Decision Analysis (Excel, Monte Carlo Business Simulation) — Fall 2024\n- Collaborated with a team to analyze financial and market data to evaluate a $150K investment in an in-house microbrewery.\n- Designed a financial model in Excel and presented insights to support the restaurant’s decision-making process.\n- Used Business Simulation Models for scenario analysis to assess potential risks and returns.\n\n\n\n\n\nLanguages: Mongolian (Fluent); Russian (Intermediate)\n\nInterests: Half Marathoner, Aspiring New York Marathoner, Growing Tennis Player\n\nEmail: binderiya.du@gmail.com"
  },
  {
    "objectID": "projects/project_NYC.html",
    "href": "projects/project_NYC.html",
    "title": "New York City Real Estate Analysis: Far Rockaway",
    "section": "",
    "text": "This project analyzes the real estate market in Far Rockaway, New York, to determine investment opportunities and market trends. By examining historical data and forecasting future sales, we explore which property segments offer the best potential for growth."
  },
  {
    "objectID": "projects/project_NYC.html#project-overview",
    "href": "projects/project_NYC.html#project-overview",
    "title": "New York City Real Estate Analysis: Far Rockaway",
    "section": "",
    "text": "This project analyzes the real estate market in Far Rockaway, New York, to determine investment opportunities and market trends. By examining historical data and forecasting future sales, we explore which property segments offer the best potential for growth."
  },
  {
    "objectID": "projects/project_NYC.html#data-analysis",
    "href": "projects/project_NYC.html#data-analysis",
    "title": "New York City Real Estate Analysis: Far Rockaway",
    "section": "Data Analysis",
    "text": "Data Analysis\nWe began with a dataset containing real estate transactions in Far Rockaway, which included 8,781 rows of data. After filtering for residential properties, we were left with 8,113 rows of relevant data. Key findings include:\n\nThe most frequent sale price range is between $250,000 and $500,000.\nMarket trends show a significant dip in sales after the 2008 recession, with a slow recovery post-2016."
  },
  {
    "objectID": "projects/project_NYC.html#clustering-and-market-segments",
    "href": "projects/project_NYC.html#clustering-and-market-segments",
    "title": "New York City Real Estate Analysis: Far Rockaway",
    "section": "Clustering and Market Segments",
    "text": "Clustering and Market Segments\nUsing clustering analysis, we identified five distinct property segments in Far Rockaway:\n\nCluster 1: Average-sized, newer properties with below-average sale prices.\nCluster 2: Newer, moderately sized properties with above-average sale prices.\nCluster 3: Smaller, older homes with average sale prices.\nCluster 4: Larger, high-value luxury homes or large commercial properties.\nCluster 5: Smaller, older homes with lower prices.\n\nThese clusters help identify which property types are expected to perform well in the future, particularly for young professionals seeking modern housing."
  },
  {
    "objectID": "projects/project_NYC.html#sales-forecasting",
    "href": "projects/project_NYC.html#sales-forecasting",
    "title": "New York City Real Estate Analysis: Far Rockaway",
    "section": "Sales Forecasting",
    "text": "Sales Forecasting\nWe performed a sales trajectory forecasting analysis, which revealed that newer properties are more likely to benefit from the current recovery, driven by infrastructure improvements and increased interest from younger professionals.\n\nProjected growth in sales is expected in neighborhoods with modern properties, with the demand for these properties expected to rise."
  },
  {
    "objectID": "projects/project_NYC.html#investment-recommendations",
    "href": "projects/project_NYC.html#investment-recommendations",
    "title": "New York City Real Estate Analysis: Far Rockaway",
    "section": "Investment Recommendations",
    "text": "Investment Recommendations\nBased on the analysis and clustering results, we recommend investing in newer properties in Far Rockaway, particularly those with an optimal size of around 3,000 sq ft. Key reasons for this recommendation include:\n\nHigh tenant appeal due to modern designs and reduced vacancy rates.\nLower maintenance costs for newer properties.\nStrong market performance, with newer properties showing higher sales than older real estate."
  },
  {
    "objectID": "projects/project_NYC.html#conclusion",
    "href": "projects/project_NYC.html#conclusion",
    "title": "New York City Real Estate Analysis: Far Rockaway",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the analysis of Far Rockaway’s real estate market reveals strong investment potential, particularly in newer properties. These properties offer a balance of high returns with lower risk, especially with the expected growth in sales driven by urban developments and infrastructure projects. This project demonstrates how data can inform strategic decisions in the real estate market."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Hi, I’m Binderiya Dugersuren, a Master’s student at Boston University pursuing a Master’s degree in Applied Business Analytics. I’m passionate about data science and using it to make businesses more sustainable. When I’m not diving into data, you’ll find me exploring new places around the world."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About me",
    "section": "Education",
    "text": "Education\nBoston University | Boston, MA\nMS in Applied Business Analytics | Sept 2024 - June 2026\nUniversity of Minnesota - Twin Cities| Minneapolis, MN\nB.S in Sustainable Systems Management | Sept 2016 - January 2020"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About me",
    "section": "Experience",
    "text": "Experience\nBoston University | Reaserch Assistant | October 2024 - present\nConduct consultation sessions to assist students with course material, clarify concepts, and address academic concerns. Support grading assignments for a class with 25 students to ensure fair and timely evaluation.\nKhev Khashmal | Business Development Executive Assistant\nUlaanbaatar, Mongolia | June 2021 - August 2024\nCollaborated with management consultants and stakeholders to develop strategies for market expansion and operational efficiency, successfully reducing operational costs by 5% despite launching a new production line and factory. Led cross-functional coordination to optimize workflows for smooth integration of new processes.\nClean Water Action | Sustainability Advocate Intern\nMinneapolis, MN | June 2019 – August 2019\nCommunicated complex environmental policies through presentations and educational sessions, effectively informing and engaging new members on key sustainability issues. Led grassroots outreach initiatives to mobilize community support for environmental policies, increasing public awareness and advocacy engagement."
  },
  {
    "objectID": "about.html#future-goals",
    "href": "about.html#future-goals",
    "title": "About me",
    "section": "Future Goals",
    "text": "Future Goals\nIn the future, I hope to work with organizations that aim to drive sustainable growth through data-driven decision-making. I’m eager to leverage my skills in analytics to help businesses minimize waste, optimize resources, and operate more sustainably."
  },
  {
    "objectID": "about.html#hobbies",
    "href": "about.html#hobbies",
    "title": "About me",
    "section": "Hobbies",
    "text": "Hobbies\nOutside of academics, I’m an avid traveler. I love discovering new cultures and landscapes, and I try to bring that curiosity and excitement into everything I do. I’m also a passionate runner and am training for my first marathon."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Binderiya Dugsuren",
    "section": "",
    "text": "Exploring theworld, one data point at a time\n  \n\n\n   TRAVELER & LEARNER   |   DATA SCIENCE ENTHUSIAST   |   SUSTAINABILITY ADVOCATE   |   HALF MARATHONER & ASPIRING NYC MARATHONER\n\n\n\n\n\n\n\nAs a young child exploring the vast Mongolian steppe, I developed a deep curiosity about new places, cultures, and ideas. This passion for exploration has stayed with me throughout my life and now drives my work in data science. With a background in sustainability, I aim to help businesses not only succeed but also operate responsibly and sustainably.\nWhile I’m just beginning my journey in data science, I’m eager to dive deeper into this field and learn how data can be leveraged to solve real-world problems. My mission is to harness the power of data to create sustainable solutions for businesses—whether it’s optimizing resources, reducing waste, or making smarter decisions that benefit both people and the planet."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Binderiya Dugersuren",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\ndf = pd.read_csv(\"lightcast_job_postings.csv\")\nprint(\"Available columns in dataset:\", df.columns.tolist())\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\n\ndf.drop(columns=columns_to_drop, inplace=True)\nprint(\"Dropped unnecessary columns.\")\nprint(df.columns)\n\n# handle missing value\nprint(\"Missing values before cleaning:\")\nprint(df.isnull().sum())\n\n\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\n# Check column names\ndf.columns = df.columns.str.upper().str.strip()  # Normalize column names\nprint(df.columns)  # Debugging step\n\n# Visualize missing data\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Check if \"SALARY\" exists before filling missing values\nif \"SALARY\" in df.columns:\n    df[\"SALARY\"].fillna(df[\"SALARY\"].median(), inplace=True)\nelse:\n    print(\"⚠️ Warning: 'SALARY' column not found in dataframe!\")\n\n# Check if \"INDUSTRY\" exists before filling missing values\nif \"INDUSTRY\" in df.columns:\n    df[\"INDUSTRY\"].fillna(\"Unknown\", inplace=True)\nelse:\n    print(\"⚠️ Warning: 'INDUSTRY' column not found in dataframe!\")\n\nprint(\"✅ Missing value handling complete.\")\n\n# delete duplicates\ndf = df.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"])\nprint(\"Duplicates removed.\")\n\nAvailable columns in dataset: ['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\nDropped unnecessary columns.\nIndex(['LAST_UPDATED_DATE', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES',\n       'SOURCES', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY',\n       'MODELED_EXPIRED',\n       ...\n       'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3',\n       'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME',\n       'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6',\n       'NAICS_2022_6_NAME'],\n      dtype='object', length=118)\nMissing values before cleaning:\nLAST_UPDATED_DATE        0\nPOSTED                   0\nEXPIRED               7822\nDURATION             27294\nSOURCE_TYPES             0\n                     ...  \nNAICS_2022_4_NAME        0\nNAICS_2022_5             0\nNAICS_2022_5_NAME        0\nNAICS_2022_6             0\nNAICS_2022_6_NAME        0\nLength: 118, dtype: int64\nIndex(['LAST_UPDATED_DATE', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES',\n       'SOURCES', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY',\n       'MODELED_EXPIRED',\n       ...\n       'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3',\n       'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME',\n       'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6',\n       'NAICS_2022_6_NAME'],\n      dtype='object', length=118)\n\n\n\n\n\n\n\n\n\n⚠️ Warning: 'SALARY' column not found in dataframe!\n⚠️ Warning: 'INDUSTRY' column not found in dataframe!\n✅ Missing value handling complete.\nDuplicates removed.\n\n\n\nif \"SALARY\" in df.columns:\n    df[\"SALARY\"].fillna(df[\"SALARY\"].median(), inplace=True)\nelse:\n    print(\"⚠️ Warning: 'SALARY' column not found in dataframe!\")\n\n⚠️ Warning: 'SALARY' column not found in dataframe!\n\n\n\n# identifying data analyst jobs by keyword searching\nkeywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n            'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n            'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n            'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n\nmatch = lambda col: df[col].str.contains('|'.join(keywords), case=False, na=False)\n\ndf['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n             | match('SKILLS_NAME') \\\n             | match('SPECIALIZED_SKILLS_NAME') \ndf['DATA_ANALYST_JOB'].value_counts()\n\nDATA_ANALYST_JOB\nFalse    37052\nTrue     32148\nName: count, dtype: int64\n\n\n\ndf['DATA_ANALYST_JOB']\n\n0        False\n1        False\n2         True\n3        False\n4        False\n         ...  \n72471     True\n72472     True\n72473     True\n72474     True\n72475    False\nName: DATA_ANALYST_JOB, Length: 69200, dtype: bool\n\n\n\nimport plotly.express as px\n\n# Define custom colors for 'True' and 'False' categories\ncolor_map = {\n    False: \"#d62728\" ,   # Red\n    True: \"#3BB143 \"   # Green\n}\n\n\nfig = px.bar(df_grouped, \n             x='NAICS2_NAME', \n             y='Job_Count',\n             color='DATA_ANALYST_JOB',\n             title=\"Data Analytics & Business Analytics Job Trends\",\n              labels={'NAICS2_NAME': 'Industry', 'Job_Count': 'Number of Jobs'},\n             barmode='group',\n             color_discrete_map=color_map  # Custom colors\n            )\n\nfig.update_layout(\n    yaxis=dict(\n        title=\"Number of Jobs\", \n        range=[0, df_grouped['Job_Count'].max() * 1.2]  # Increase y-axis height\n    ),\n    height=700,  # Make the figure taller\n    xaxis=dict(\n        tickangle=-45  # Rotate x-axis labels for better readability\n    )\n)\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nimport plotly.express as px\n\n# Identify the top 2 industries with the most data analyst jobs\ntop_industries = df_grouped.groupby(\"NAICS2_NAME\")[\"Job_Count\"].sum().nlargest(10).index\n\n# Filter the original grouped DataFrame, not the raw df\ndf_top_industries = df_grouped[df_grouped[\"NAICS2_NAME\"].isin(top_industries)]\n\n# Create the bar chart to analyze job counts within these industries\nfig = px.bar(df_top_industries, \n             x=\"DATA_ANALYST_JOB\", \n             y=\"Job_Count\", \n             color=\"NAICS2_NAME\",\n             title=\"Top 2 Industries Hiring Data Analysts\",\n             labels={'DATA_ANALYST_JOB': 'Job Title', 'Job_Count': 'Number of Jobs'},\n             barmode='group')\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n# Define target industries\ntarget_industries = [\"Finance and Insurance\", \"Health Care and Social Assistance\"]\n\n# Filter the DataFrame\ndf_skills = df[df[\"NAICS2_NAME\"].isin(target_industries)]\n\n\nimport plotly.express as px\n\n# Define target industries\ntarget_industries = [\"Finance and Insurance\", \"Health Care and Social Assistance\"]\n\n# Filter the original DataFrame (df) instead of df_grouped\ndf_remote = df[df[\"NAICS2_NAME\"].isin(target_industries)]\n\n# Count occurrences of each remote type in these industries\ndf_remote_grouped = df_remote.groupby(\"REMOTE_TYPE_NAME\").size().reset_index(name=\"Count\")\n\n# Create a pie chart\nfig = px.pie(df_remote_grouped, \n             names=\"REMOTE_TYPE_NAME\", \n             values=\"Count\", \n             title=\"Remote vs. On-Site Data Analyst Jobs in Finance & Healthcare\",\n             color=\"REMOTE_TYPE_NAME\", \n             color_discrete_map={\"Remote\": \"#1f77b4\", \"On-Site\": \"#d62728\", \"Hybrid\": \"#2ca02c\"})\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "projects/analysis.html",
    "href": "projects/analysis.html",
    "title": "Exploratory Data Analysis on Data Analytics Job Trends",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\ndf = pd.read_csv(\"lightcast_job_postings.csv\")\nprint(\"Available columns in dataset:\", df.columns.tolist())\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\n\ndf.drop(columns=columns_to_drop, inplace=True)\nprint(\"Dropped unnecessary columns.\")\nprint(df.columns)\n\n# handle missing value\nprint(\"Missing values before cleaning:\")\nprint(df.isnull().sum())\n\n\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\n# Check column names\ndf.columns = df.columns.str.upper().str.strip()  # Normalize column names\nprint(df.columns)  # Debugging step\n\n# Visualize missing data\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Check if \"SALARY\" exists before filling missing values\nif \"SALARY\" in df.columns:\n    df[\"SALARY\"].fillna(df[\"SALARY\"].median(), inplace=True)\nelse:\n    print(\"⚠️ Warning: 'SALARY' column not found in dataframe!\")\n\n# Check if \"INDUSTRY\" exists before filling missing values\nif \"INDUSTRY\" in df.columns:\n    df[\"INDUSTRY\"].fillna(\"Unknown\", inplace=True)\nelse:\n    print(\"⚠️ Warning: 'INDUSTRY' column not found in dataframe!\")\n\nprint(\"✅ Missing value handling complete.\")\n\n# delete duplicates\ndf = df.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"])\nprint(\"Duplicates removed.\")\n\n\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[1], line 4\n      2 import matplotlib.pyplot as plt\n      3 import plotly.express as px\n----&gt; 4 df = pd.read_csv(\"lightcast_job_postings.csv\")\n      5 print(\"Available columns in dataset:\", df.columns.tolist())\n      7 columns_to_drop = [\n      8     \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n      9     \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n     10     \"SOC_2\", \"SOC_3\", \"SOC_5\"\n     11 ]\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: 'lightcast_job_postings.csv'\n\n\n\n\nif \"SALARY\" in df.columns:\n    df[\"SALARY\"].fillna(df[\"SALARY\"].median(), inplace=True)\nelse:\n    print(\"⚠️ Warning: 'SALARY' column not found in dataframe!\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[2], line 1\n----&gt; 1 if \"SALARY\" in df.columns:\n      2     df[\"SALARY\"].fillna(df[\"SALARY\"].median(), inplace=True)\n      3 else:\n\nNameError: name 'df' is not defined\n\n\n\n\n# identifying data analyst jobs by keyword searching\nkeywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n            'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n            'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n            'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n\nmatch = lambda col: df[col].str.contains('|'.join(keywords), case=False, na=False)\n\ndf['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n             | match('SKILLS_NAME') \\\n             | match('SPECIALIZED_SKILLS_NAME') \ndf['DATA_ANALYST_JOB'].value_counts()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 9\n      2 keywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n      3             'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n      4             'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n      5             'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n      7 match = lambda col: df[col].str.contains('|'.join(keywords), case=False, na=False)\n----&gt; 9 df['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n     10              | match('SKILLS_NAME') \\\n     11              | match('SPECIALIZED_SKILLS_NAME') \n     12 df['DATA_ANALYST_JOB'].value_counts()\n\nCell In[3], line 7, in &lt;lambda&gt;(col)\n      1 # identifying data analyst jobs by keyword searching\n      2 keywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n      3             'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n      4             'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n      5             'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n----&gt; 7 match = lambda col: df[col].str.contains('|'.join(keywords), case=False, na=False)\n      9 df['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n     10              | match('SKILLS_NAME') \\\n     11              | match('SPECIALIZED_SKILLS_NAME') \n     12 df['DATA_ANALYST_JOB'].value_counts()\n\nNameError: name 'df' is not defined\n\n\n\n\ndf['DATA_ANALYST_JOB']\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[4], line 1\n----&gt; 1 df['DATA_ANALYST_JOB']\n\nNameError: name 'df' is not defined\n\n\n\n\nimport plotly.express as px\n\n# Define custom colors for 'True' and 'False' categories\ncolor_map = {\n    False: \"#d62728\" ,   # Red\n    True: \"#3BB143 \"   # Green\n}\n\n\nfig = px.bar(df_grouped, \n             x='NAICS2_NAME', \n             y='Job_Count',\n             color='DATA_ANALYST_JOB',\n             title=\"Data Analytics & Business Analytics Job Trends\",\n              labels={'NAICS2_NAME': 'Industry', 'Job_Count': 'Number of Jobs'},\n             barmode='group',\n             color_discrete_map=color_map  # Custom colors\n            )\n\nfig.update_layout(\n    yaxis=dict(\n        title=\"Number of Jobs\", \n        range=[0, df_grouped['Job_Count'].max() * 1.2]  # Increase y-axis height\n    ),\n    height=700,  # Make the figure taller\n    xaxis=dict(\n        tickangle=-45  # Rotate x-axis labels for better readability\n    )\n)\n\nfig.show()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[5], line 10\n      3 # Define custom colors for 'True' and 'False' categories\n      4 color_map = {\n      5     False: \"#d62728\" ,   # Red\n      6     True: \"#3BB143 \"   # Green\n      7 }\n---&gt; 10 fig = px.bar(df_grouped, \n     11              x='NAICS2_NAME', \n     12              y='Job_Count',\n     13              color='DATA_ANALYST_JOB',\n     14              title=\"Data Analytics & Business Analytics Job Trends\",\n     15               labels={'NAICS2_NAME': 'Industry', 'Job_Count': 'Number of Jobs'},\n     16              barmode='group',\n     17              color_discrete_map=color_map  # Custom colors\n     18             )\n     20 fig.update_layout(\n     21     yaxis=dict(\n     22         title=\"Number of Jobs\", \n   (...)\n     28     )\n     29 )\n     31 fig.show()\n\nNameError: name 'df_grouped' is not defined\n\n\n\nThe bar graph compares job trends across various industries, highlighting the number of job openings for data analysts (green bars) versus other job titles (red bars). It shows that industries like Administrative Support and Waste Management, Retail Trade, and Information are seeing significant demand for data analysts, with a noticeable gap between these jobs and others in many sectors.\n\nimport plotly.express as px\n\n# Identify the top 2 industries with the most data analyst jobs\ntop_industries = df_grouped.groupby(\"NAICS2_NAME\")[\"Job_Count\"].sum().nlargest(10).index\n\n# Filter the original grouped DataFrame, not the raw df\ndf_top_industries = df_grouped[df_grouped[\"NAICS2_NAME\"].isin(top_industries)]\n\n# Create the bar chart to analyze job counts within these industries\nfig = px.bar(df_top_industries, \n             x=\"DATA_ANALYST_JOB\", \n             y=\"Job_Count\", \n             color=\"NAICS2_NAME\",\n             title=\"Top 2 Industries Hiring Data Analysts\",\n             labels={'DATA_ANALYST_JOB': 'Job Title', 'Job_Count': 'Number of Jobs'},\n             barmode='group')\n\nfig.show()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[6], line 4\n      1 import plotly.express as px\n      3 # Identify the top 2 industries with the most data analyst jobs\n----&gt; 4 top_industries = df_grouped.groupby(\"NAICS2_NAME\")[\"Job_Count\"].sum().nlargest(10).index\n      6 # Filter the original grouped DataFrame, not the raw df\n      7 df_top_industries = df_grouped[df_grouped[\"NAICS2_NAME\"].isin(top_industries)]\n\nNameError: name 'df_grouped' is not defined\n\n\n\nThe second graph displays the top 10 industries hiring data analysts, with the Administrative Support and Waste Management industry having the highest number of data analyst job openings. The graph uses different colors to represent job titles in various industries, with Educational Services and Retail Trade showing a considerable number of open positions as well.\n\n# Define target industries\ntarget_industries = [\"Finance and Insurance\", \"Health Care and Social Assistance\"]\n\n# Filter the DataFrame\ndf_skills = df[df[\"NAICS2_NAME\"].isin(target_industries)]\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 5\n      2 target_industries = [\"Finance and Insurance\", \"Health Care and Social Assistance\"]\n      4 # Filter the DataFrame\n----&gt; 5 df_skills = df[df[\"NAICS2_NAME\"].isin(target_industries)]\n\nNameError: name 'df' is not defined\n\n\n\n\nimport plotly.express as px\n\n# Define target industries\ntarget_industries = [\"Finance and Insurance\", \"Health Care and Social Assistance\"]\n\n# Filter the original DataFrame (df) instead of df_grouped\ndf_remote = df[df[\"NAICS2_NAME\"].isin(target_industries)]\n\n# Count occurrences of each remote type in these industries\ndf_remote_grouped = df_remote.groupby(\"REMOTE_TYPE_NAME\").size().reset_index(name=\"Count\")\n\n# Create a pie chart\nfig = px.pie(df_remote_grouped, \n             names=\"REMOTE_TYPE_NAME\", \n             values=\"Count\", \n             title=\"Remote vs. On-Site Data Analyst Jobs in Finance & Healthcare\",\n             color=\"REMOTE_TYPE_NAME\", \n             color_discrete_map={\"Remote\": \"#1f77b4\", \"On-Site\": \"#d62728\", \"Hybrid\": \"#2ca02c\"})\n\nfig.show()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[8], line 7\n      4 target_industries = [\"Finance and Insurance\", \"Health Care and Social Assistance\"]\n      6 # Filter the original DataFrame (df) instead of df_grouped\n----&gt; 7 df_remote = df[df[\"NAICS2_NAME\"].isin(target_industries)]\n      9 # Count occurrences of each remote type in these industries\n     10 df_remote_grouped = df_remote.groupby(\"REMOTE_TYPE_NAME\").size().reset_index(name=\"Count\")\n\nNameError: name 'df' is not defined\n\n\n\nThe pie chart provides a breakdown of the distribution of remote, hybrid, and on-site data analyst positions in the Finance & Healthcare sectors, with 71.5% of jobs being fully remote. The chart also indicates a smaller percentage of hybrid and on-site roles, reflecting the increasing trend toward remote work in these industries."
  }
]